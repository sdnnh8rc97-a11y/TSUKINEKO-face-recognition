# ===============================================================
#  ä¸‰åˆä¸€è‡‰è¾¨ç³»çµ±ï¼ˆé«˜é€Ÿç‰ˆ + Anti-Drift Auto-Train + åœ˜é«”ç…§åˆ†é¡žï¼‰
#  ä½œè€…ï¼šã¾ã•ãå°ˆç”¨ï¼ˆV3.1 å®‰å…¨ç‰ˆï¼‰
# ===============================================================

import os
import cv2
import numpy as np
from tqdm import tqdm
from insightface.app import FaceAnalysis
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
import pickle


# ---------------------------------------------------------------
# è¨­å®šè·¯å¾‘ï¼ˆå¯è‡ªè¡Œèª¿æ•´ï¼‰
# ---------------------------------------------------------------
RAW_ROOT = "/content/drive/MyDrive/face_DataSet/face_raw"                 
CACHE_ROOT = "/content/drive/MyDrive/face_DataSet/face_emb_cache"
CLASSIFY_SAVE = "/content/drive/MyDrive/face_DataSet/face_clean_group"
GROUP_PHOTO = "/content/drive/MyDrive/test_faces/ä¿å…¨groupæ¸¬è©¦/19534.jpg"


# ---------------------------------------------------------------
# åˆå§‹åŒ– InsightFace
# ---------------------------------------------------------------
app = FaceAnalysis(name="buffalo_l")
app.prepare(ctx_id=0, det_size=(640, 640))


# ===============================================================
#  STEP 1 â€” å»ºç«‹ embedding cache
# ===============================================================
def build_cache():
    os.makedirs(CACHE_ROOT, exist_ok=True)

    persons = sorted([
        p for p in os.listdir(RAW_ROOT)
        if os.path.isdir(os.path.join(RAW_ROOT, p))
    ])

    print("ðŸ“Œ åµæ¸¬åˆ°äººå“¡è³‡æ–™å¤¾ï¼š", persons)

    for person in persons:
        raw_dir = os.path.join(RAW_ROOT, person)
        cache_dir = os.path.join(CACHE_ROOT, person)
        os.makedirs(cache_dir, exist_ok=True)

        photos = [
            f for f in os.listdir(raw_dir)
            if f.lower().endswith((".jpg", ".png", ".jpeg"))
        ]

        print(f"\n==============================")
        print(f"ðŸ‘¤ {person} â€” {len(photos)} å¼µç…§ç‰‡")
        print("==============================")

        for img_name in tqdm(photos, desc=f"å»ºç«‹ cacheï¼š{person}", ncols=80):
            raw_path = os.path.join(raw_dir, img_name)
            cache_path = os.path.join(cache_dir, img_name + ".npy")

            # cache å·²å­˜åœ¨ â†’ è·³éŽï¼ˆç§’è·‘ï¼‰
            if os.path.exists(cache_path):
                continue

            img = cv2.imread(raw_path)
            if img is None:
                continue

            faces = app.get(img)
            if len(faces) == 0:
                continue

            emb = faces[0].normed_embedding
            np.save(cache_path, emb)

    print("\nðŸŽ‰ STEP1 å®Œæˆï¼šcache å»ºç«‹å®Œç•¢ï¼")


# ===============================================================
#  STEP 2 â€” å¾ž cache å»ºç«‹è³‡æ–™åº«ï¼ˆå¹³å‡ embeddingï¼‰
# ===============================================================
def load_database():
    db = {}

    for person in os.listdir(CACHE_ROOT):
        p_dir = os.path.join(CACHE_ROOT, person)
        if not os.path.isdir(p_dir):
            continue

        embs = []
        for f in os.listdir(p_dir):
            if f.endswith(".npy"):
                emb = np.load(os.path.join(p_dir, f))
                embs.append(emb)

        if len(embs) > 0:
            db[person] = np.mean(embs, axis=0)
            print(f"âœ” è³‡æ–™åº«ï¼š{person}ï¼ˆ{len(embs)} ç­† embeddingï¼‰")

    return db


# ===============================================================
#  STEP 2.1 â€” Cluster Statsï¼ˆä¸­å¿ƒï¼‹æ¨™æº–å·®ï¼‰
# ===============================================================
def build_db_stats():
    stats = {}

    for person in os.listdir(CACHE_ROOT):
        p_dir = os.path.join(CACHE_ROOT, person)
        if not os.path.isdir(p_dir):
            continue

        embs = []
        for f in os.listdir(p_dir):
            if f.endswith(".npy"):
                embs.append(np.load(os.path.join(p_dir, f)))

        if len(embs) >= 3:
            emb_arr = np.vstack(embs)
            stats[person] = {
                "center": np.mean(emb_arr, axis=0),
                "std": np.std(emb_arr, axis=0).mean()
            }

    return stats


# ===============================================================
# è‡ªå‹•æ›´æ–° cacheï¼ˆraw+embeddingï¼‰
# ===============================================================
def update_cache_for(person, emb, filename):
    cache_dir = os.path.join(CACHE_ROOT, person)
    os.makedirs(cache_dir, exist_ok=True)

    cache_path = os.path.join(cache_dir, filename + ".npy")
    np.save(cache_path, emb)

    print(f"ðŸ”„ Auto-Cacheï¼šå·²å¯«å…¥ â†’ {cache_path}")


# ===============================================================
# é‡æ–°è¨“ç·´ SVM / KNNï¼ˆä¸‰åˆ†é¡žå™¨ï¼‰
# ===============================================================
def retrain_models(cache_root=CACHE_ROOT):

    X = []
    y = []

    for person in sorted(os.listdir(cache_root)):
        p_dir = os.path.join(cache_root, person)
        if not os.path.isdir(p_dir):
            continue

        for f in os.listdir(p_dir):
            if f.endswith(".npy"):
                emb = np.load(os.path.join(p_dir, f))
                X.append(emb)
                y.append(person)

    X = np.array(X)
    y = np.array(y)

    print(f"ðŸ“Œ retrain æ¨£æœ¬æ•¸ï¼š{len(X)}")

    # Train SVM
    print("ðŸ”§ è¨“ç·´ SVM ...")
    svm = SVC(kernel='linear', probability=True)
    svm.fit(X, y)
    pickle.dump(svm, open(os.path.join(cache_root, "svm.pkl"), "wb"))

    # Train KNN
    print("ðŸ”§ è¨“ç·´ KNN ...")
    knn = KNeighborsClassifier(n_neighbors=3, metric='cosine')
    knn.fit(X, y)
    pickle.dump(knn, open(os.path.join(cache_root, "knn.pkl"), "wb"))

    print("ðŸŽ‰ Retrain å®Œæˆï¼")
    return svm, knn


# å…ˆè¼‰å…¥ä¸€æ¬¡
svm_model, knn_model = retrain_models()


# ===============================================================
# Ensembleï¼ˆä¸‰åˆ†é¡žå™¨æŠ•ç¥¨ï¼‰
# ===============================================================
def ensemble_predict(emb, db, svm, knn, cos_threshold=0.38):

    # Cosine
    best_person, best_score = "Unknown", -1
    for person, center in db.items():
        score = float(np.dot(emb, center))
        if score > best_score:
            best_score = score
            best_person = person

    cosine_pred = best_person if best_score >= cos_threshold else "Unknown"

    # SVM
    svm_pred = svm.predict([emb])[0]
    svm_conf = max(svm.predict_proba([emb])[0])

    # KNN
    knn_pred = knn.predict([emb])[0]

    # Voting
    votes = [cosine_pred, svm_pred, knn_pred]
    final = max(votes, key=votes.count)

    return final, {
        "cosine_pred": cosine_pred,
        "cosine_conf": best_score,
        "svm_pred": svm_pred,
        "svm_conf": svm_conf,
        "knn_pred": knn_pred
    }


# ===============================================================
# V3.1 Auto-Train åˆ¤æ–·ï¼ˆä¼æ¥­ç´š Anti-Driftï¼‰
# ===============================================================
def allow_auto_train(final_pred, details, emb, db_stats):

    cosine_ok = details["cosine_conf"] >= 0.78
    svm_ok = details["svm_conf"] >= 0.85

    consistent = (
        details["cosine_pred"] == final_pred and
        details["svm_pred"] == final_pred and
        details["knn_pred"] == final_pred
    )

    if not (cosine_ok and svm_ok and consistent):
        return False

    # Cluster Distance Check
    center = db_stats[final_pred]["center"]
    std = db_stats[final_pred]["std"]

    dist = np.linalg.norm(emb - center)
    max_allowed = std * 1.2

    return dist <= max_allowed


# ===============================================================
# STEP 3 â€” åœ˜é«”ç…§åˆ†é¡žï¼ˆå« Auto-Train V3.1ï¼‰
# ===============================================================
def classify_group_photo():
    global svm_model, knn_model

    os.makedirs(CLASSIFY_SAVE, exist_ok=True)

    img = cv2.imread(GROUP_PHOTO)
    faces = app.get(img)

    faces = sorted(faces, key=lambda f: f.bbox[0])  # å·¦â†’å³æŽ’åº
    db_stats = build_db_stats()

    print(f"\nðŸ“¸ åµæ¸¬åˆ° {len(faces)} å¼µè‡‰ï¼ˆå·²æŽ’åºï¼‰\n")

    for i, f in enumerate(faces):
        x1, y1, x2, y2 = map(int, f.bbox)
        crop = img[y1:y2, x1:x2]
        emb = f.normed_embedding

        final_pred, details = ensemble_predict(emb, database, svm_model, knn_model)

        save_dir = os.path.join(CLASSIFY_SAVE, final_pred)
        os.makedirs(save_dir, exist_ok=True)
        out_path = os.path.join(save_dir, f"group_{i+1}.jpg")
        cv2.imwrite(out_path, crop)

        print(f"è‡‰ {i+1}: æœ€çµ‚åˆ†é¡ž â†’ {final_pred}")
        print(details)

        # --- Auto-Train V3.1 ---
        if final_pred != "Unknown" and final_pred in db_stats:
            if allow_auto_train(final_pred, details, emb, db_stats):

                auto_raw_dir = os.path.join(RAW_ROOT, final_pred)
                os.makedirs(auto_raw_dir, exist_ok=True)

                add_path = os.path.join(auto_raw_dir, f"auto_{i+1}.jpg")
                cv2.imwrite(add_path, crop)

                print(f"âœ… Auto-Trainï¼šæ–°å¢ž raw â†’ {add_path}")

                update_cache_for(final_pred, emb, f"auto_{i+1}")

            else:
                print("âš ï¸ Auto-Train è·³éŽï¼ˆä¿¡å¿ƒæˆ– cluster è·é›¢ä¸è¶³ï¼‰")
        else:
            print("âš ï¸ æœªåŠ å…¥ Auto-Trainï¼ˆUnknown æˆ– stats ä¸è¶³ï¼‰")

    # Retrain ä¸€æ¬¡
    print("\nðŸ”„ Auto retrainï¼ˆä¸‰åˆ†é¡žå™¨ï¼‰...")
    svm_model, knn_model = retrain_models()
    print("ðŸŽ‰ Auto retrain å®Œæˆï¼æ¨¡åž‹å·²æ›´æ–°")

    print("\nðŸŽ‰ STEP3 å®Œæˆï¼šåœ˜é«”ç…§åˆ†é¡žå®Œç•¢ï¼")


# ===============================================================
#  ä¸€éµåŸ·è¡Œå…¨éƒ¨æ­¥é©Ÿ
# ===============================================================
print("\nðŸš€ STEP1ï¼šé–‹å§‹å»ºç«‹ embedding cache ...")
build_cache()

print("\nðŸš€ STEP2ï¼šå»ºç«‹è³‡æ–™åº« ...")
database = load_database()

print("\nðŸš€ STEP3ï¼šé–‹å§‹è™•ç†åœ˜é«”ç…§ ...")
classify_group_photo()

print("\nðŸŽ‰ å…¨æµç¨‹å®Œæˆï¼")

