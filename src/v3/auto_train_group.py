# ===============================================================
#  ä¸‰åˆä¸€è‡‰è¾¨ç³»çµ±ï¼ˆé«˜é€Ÿç‰ˆ + è³‡æ–™åº« + åœ˜é«”ç…§åˆ†é¡ï¼‰
#  ä½œè€…ï¼šã¾ã•ãå°ˆç”¨
# ===============================================================

import os
import cv2
import numpy as np
from tqdm import tqdm
from insightface.app import FaceAnalysis
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
import pickle


# ---------------------------------------------------------------
# è¨­å®šè·¯å¾‘ï¼ˆå¯è‡ªè¡Œèª¿æ•´ï¼‰
# ---------------------------------------------------------------
RAW_ROOT = "/content/drive/MyDrive/face_DataSet/face_raw"                 
CACHE_ROOT = "/content/drive/MyDrive/face_DataSet/face_emb_cache" # cache æœƒå­˜ .npy
CLASSIFY_SAVE = "/content/drive/MyDrive/face_DataSet/face_clean_group"  # åˆ†é¡å¾Œçš„è£åˆ‡è‡‰ç…§
GROUP_PHOTO = "/content/drive/MyDrive/test_faces/ä¿å…¨groupæ¸¬è©¦/19534.jpg"  # åœ˜é«”ç…§


# ---------------------------------------------------------------
# åˆå§‹åŒ– InsightFace
# ---------------------------------------------------------------
app = FaceAnalysis(name="buffalo_l")
app.prepare(ctx_id=0, det_size=(640, 640))


# ===============================================================
#  STEP 1 â€” å»ºç«‹ embedding cacheï¼ˆç¬¬ä¸€æ¬¡è·‘è¼ƒä¹…ï¼Œä¹‹å¾Œç§’è·‘ï¼‰
# ===============================================================
def build_cache():
    os.makedirs(CACHE_ROOT, exist_ok=True)

    persons = sorted([
        p for p in os.listdir(RAW_ROOT)
        if os.path.isdir(os.path.join(RAW_ROOT, p))
    ])

    print("ğŸ“Œ åµæ¸¬åˆ°äººå“¡è³‡æ–™å¤¾ï¼š", persons)

    for person in persons:
        raw_dir = os.path.join(RAW_ROOT, person)
        cache_dir = os.path.join(CACHE_ROOT, person)
        os.makedirs(cache_dir, exist_ok=True)

        photos = [
            f for f in os.listdir(raw_dir)
            if f.lower().endswith((".jpg", ".png", ".jpeg"))
        ]

        print(f"\n==============================")
        print(f"ğŸ‘¤ {person} â€” {len(photos)} å¼µç…§ç‰‡")
        print("==============================")

        for img_name in tqdm(photos, desc=f"å»ºç«‹ cacheï¼š{person}", ncols=80):
            raw_path = os.path.join(raw_dir, img_name)
            cache_path = os.path.join(cache_dir, img_name + ".npy")

            # cache å·²å­˜åœ¨ â†’ è·³éï¼ˆç§’è·‘ï¼‰
            if os.path.exists(cache_path):
                continue

            img = cv2.imread(raw_path)
            if img is None:
                continue

            faces = app.get(img)
            if len(faces) == 0:
                continue

            emb = faces[0].normed_embedding
            np.save(cache_path, emb)

    print("\nğŸ‰ STEP1 å®Œæˆï¼šcache å»ºç«‹å®Œç•¢ï¼")


# ===============================================================
#  STEP 2 â€” å¾ cache å»ºç«‹è³‡æ–™åº«ï¼ˆç§’è¼‰å…¥ï¼‰
# ===============================================================
def load_database():
    db = {}

    for person in os.listdir(CACHE_ROOT):
        p_dir = os.path.join(CACHE_ROOT, person)
        if not os.path.isdir(p_dir):
            continue

        embs = []
        for f in os.listdir(p_dir):
            if f.endswith(".npy"):
                emb = np.load(os.path.join(p_dir, f))
                embs.append(emb)

        if len(embs) > 0:
            db[person] = np.mean(embs, axis=0)
            print(f"âœ” è³‡æ–™åº«ï¼š{person}ï¼ˆ{len(embs)} ç­† embeddingï¼‰")

    return db


# Cosine æ¯”å°
def classify(emb, db, threshold=0.38):
    best_person = "unknown"
    best_score = -1

    for person, center in db.items():
        score = np.dot(emb, center)
        if score > best_score:
            best_score = score
            best_person = person

    return best_person if best_score >= threshold else "unknown"
# ===============================================================
# STEP 2.5 â€” Retrain ä¸‰åˆ†é¡å™¨ï¼ˆåƒ cache â†’ ç§’ç´šï¼‰
# ===============================================================

# ===============================================================
# è‡ªå‹•æ›´æ–° cacheï¼šå°æ–°å¢çš„ raw.jpg ç”¢ç”Ÿ embedding ä¸¦å¯«åˆ° cache
# ===============================================================
def update_cache_for(person, emb, filename):
    cache_dir = os.path.join(CACHE_ROOT, person)
    os.makedirs(cache_dir, exist_ok=True)

    # å„²å­˜ embedding
    cache_path = os.path.join(cache_dir, filename + ".npy")
    np.save(cache_path, emb)

    print(f"ğŸ”„ Auto-Cacheï¼šå·²å¯«å…¥ â†’ {cache_path}")

def retrain_models(cache_root=CACHE_ROOT):

    X = []
    y = []

    for person in sorted(os.listdir(cache_root)):
        p_dir = os.path.join(cache_root, person)
        if not os.path.isdir(p_dir):
            continue

        for f in os.listdir(p_dir):
            if f.endswith(".npy"):
                emb = np.load(os.path.join(p_dir, f))
                X.append(emb)
                y.append(person)

    X = np.array(X)
    y = np.array(y)

    print(f"ğŸ“Œ retrain æ¨£æœ¬æ•¸ï¼š{len(X)}")

    # ------ Train SVM ------
    print("ğŸ”§ è¨“ç·´ SVM ...")
    svm = SVC(kernel='linear', probability=True)
    svm.fit(X, y)
    pickle.dump(svm, open(os.path.join(cache_root, "svm.pkl"), "wb"))

    # ------ Train KNN ------
    print("ğŸ”§ è¨“ç·´ KNN ...")
    knn = KNeighborsClassifier(n_neighbors=3, metric='cosine')
    knn.fit(X, y)
    pickle.dump(knn, open(os.path.join(cache_root, "knn.pkl"), "wb"))

    print("ğŸ‰ Retrain å®Œæˆï¼")
    return svm, knn


# åŸ·è¡Œ retrainï¼ˆæ”¾åœ¨ STEP2 å¾Œé¢ï¼‰
svm_model, knn_model = retrain_models()


# ===============================================================
#  STEP 3 â€” åœ˜é«”ç…§ â†’ è£åˆ‡ â†’ æ¯”å° â†’ åˆ†é¡
# ===============================================================
# ===============================================================
#  STEP 3 â€” åœ˜é«”ç…§ â†’ è£åˆ‡ â†’ï¼ˆå·¦â†’å³æ’åºï¼‰â†’ æ¯”å° â†’ åˆ†é¡
# ===============================================================

# ===============================================================
# Ensembleï¼ˆä¸‰åˆ†é¡å™¨æŠ•ç¥¨ï¼‰
# ===============================================================

def ensemble_predict(emb, db, svm, knn, cos_threshold=0.38):

    # --- Cosine ---
    best_person, best_score = "Unknown", -1
    for person, center in db.items():
        score = float(np.dot(emb, center))
        if score > best_score:
            best_score = score
            best_person = person

    cosine_pred = best_person if best_score >= cos_threshold else "Unknown"

    # --- SVM ---
    svm_pred = svm.predict([emb])[0]
    svm_conf = max(svm.predict_proba([emb])[0])

    # --- KNN ---
    knn_pred = knn.predict([emb])[0]

    # --- Voting ---
    votes = [cosine_pred, svm_pred, knn_pred]
    final = max(votes, key=votes.count)

    return final, {
        "cosine_pred": cosine_pred,
        "cosine_conf": best_score,
        "svm_pred": svm_pred,
        "svm_conf": svm_conf,
        "knn_pred": knn_pred
    }
# ===============================================================
# STEP 3 â€” åœ˜é«”ç…§ï¼ˆå·¦â†’å³æ’åºï¼‰ï¼‹ Ensemble åˆ†é¡
# ===============================================================
def classify_group_photo():
    global svm_model, knn_model   # ğŸŸ© å¿…é ˆç§»åˆ° function æœ€ä¸Šæ–¹ï¼

    os.makedirs(CLASSIFY_SAVE, exist_ok=True)

    img = cv2.imread(GROUP_PHOTO)
    faces = app.get(img)

    # å·¦â†’å³æ’åº
    faces = sorted(faces, key=lambda f: f.bbox[0])

    print(f"\nğŸ“¸ åµæ¸¬åˆ° {len(faces)} å¼µè‡‰ï¼ˆå·²æ’åºï¼‰\n")

    for i, f in enumerate(faces):
        x1, y1, x2, y2 = map(int, f.bbox)
        crop = img[y1:y2, x1:x2]
        emb = f.normed_embedding

        # --- ä¸‰åˆ†é¡å™¨ ensemble ---
        final_pred, details = ensemble_predict(emb, database, svm_model, knn_model)

        # --- å„²å­˜è£åˆ‡è‡‰ ---
        save_dir = os.path.join(CLASSIFY_SAVE, final_pred)
        os.makedirs(save_dir, exist_ok=True)
        out_path = os.path.join(save_dir, f"group_{i+1}.jpg")
        cv2.imwrite(out_path, crop)

        print(f"è‡‰ {i+1}: æœ€çµ‚åˆ†é¡ â†’ {final_pred}")
        print(details)

        # ==========================================================
        # Auto-trainingï¼ˆå®‰å…¨ç‰ˆï¼šé«˜ä¿¡å¿ƒæ‰æœƒåŠ å…¥ï¼‰
        # ==========================================================
        if (details["cosine_conf"] >= 0.65 and 
            details["svm_conf"] >= 0.80 and 
            final_pred != "Unknown"):

            # --- 1. æ–°å¢ raw è¨“ç·´è³‡æ–™ ---
            auto_raw_dir = os.path.join(RAW_ROOT, final_pred)
            os.makedirs(auto_raw_dir, exist_ok=True)

            add_path = os.path.join(auto_raw_dir, f"auto_{i+1}.jpg")
            cv2.imwrite(add_path, crop)

            print(f"âœ… Auto-Trainï¼šæ–°å¢ raw â†’ {add_path}")

            # --- 2. è‡ªå‹•ç”¢ç”Ÿ cache (.npy) ---
            update_cache_for(final_pred, emb, f"auto_{i+1}")

        else:
            print(f"âš ï¸ Auto-Train è·³éï¼šä¿¡å¿ƒä¸è¶³ï¼Œä¸åŠ å…¥è¨“ç·´")

    # ==========================================================
    # è‡ªå‹• retrainï¼ˆä¸‰åˆ†é¡å™¨ï¼‰
    # ==========================================================
    print("\nğŸ”„ Auto retrainï¼ˆä¸‰åˆ†é¡å™¨ï¼‰...")
    svm_model, knn_model = retrain_models()
    print("ğŸ‰ Auto retrain å®Œæˆï¼æ¨¡å‹å·²æ›´æ–°")

    print("\nğŸ‰ STEP3 å®Œæˆï¼šåœ˜é«”ç…§åˆ†é¡å®Œç•¢ï¼")


# ===============================================================
#  ä¸€éµåŸ·è¡Œå…¨éƒ¨æ­¥é©Ÿ
# ===============================================================

print("\nğŸš€ STEP1ï¼šé–‹å§‹å»ºç«‹ embedding cache ...")
build_cache()

print("\nğŸš€ STEP2ï¼šå»ºç«‹è³‡æ–™åº« ...")
database = load_database()

print("\nğŸš€ STEP3ï¼šé–‹å§‹è™•ç†åœ˜é«”ç…§ ...")
classify_group_photo()

print("\nğŸ‰ å…¨æµç¨‹å®Œæˆï¼")
