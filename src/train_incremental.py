import os
import numpy as np
import cv2
import pickle
from tqdm import tqdm

from insightface.app import FaceAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC

# ============================================================
# ğŸ”§ æ¨¡å‹åç¨±ï¼ˆå»ºè­° buffalo_lï¼‰
# ============================================================
MODEL_NAME = "buffalo_l"

# ============================================================
# ğŸ”§ 1. åŸå®Œæ•´è¨“ç·´é›†ï¼ˆèˆŠä¿å…¨ï¼‰
# ğŸ”§ 2. æ–°å¢ç…§ç‰‡è³‡æ–™å¤¾ï¼ˆåªæ”¾æ–°ä¿å…¨ï¼‰
# ============================================================
RAW_DIR = "/content/drive/MyDrive/face_DataSet/face_raw"          # èˆŠçš„å®Œæ•´è³‡æ–™
NEW_DIR = "/content/drive/MyDrive/face_DataSet/face_new"          # åªæ”¾æ–°å¢ä¿å…¨çš„ç…§ç‰‡

MODEL_DIR = "src/models"
os.makedirs(MODEL_DIR, exist_ok=True)


def imread_safe(path):
    return cv2.imdecode(np.fromfile(path, dtype=np.uint8), -1)


# ============================================================
# ğŸ”¥ Step 1ï¼šè®€å–èˆŠ embeddings
# ============================================================
def load_old_data():
    X_path = os.path.join(MODEL_DIR, "X.npy")
    y_path = os.path.join(MODEL_DIR, "y.npy")

    if not os.path.exists(X_path) or not os.path.exists(y_path):
        print("âŒ æ‰¾ä¸åˆ°èˆŠè³‡æ–™ï¼Œè«‹å…ˆåšå®Œæ•´è¨“ç·´ train.py")
        exit()

    X_old = np.load(X_path)
    y_old = np.load(y_path)

    print("ğŸ“‚ è¼‰å…¥èˆŠè³‡æ–™ï¼š", X_old.shape)
    return X_old, y_old


# ============================================================
# ğŸ”¥ Step 2ï¼šè®€å–å¢é‡è³‡æ–™ï¼ˆåªè·‘ new è³‡æ–™å¤¾ï¼‰
# ============================================================
def load_new_embeddings():
    app = FaceAnalysis(name=MODEL_NAME)
    app.prepare(ctx_id=0)

    X_new = []
    y_new = []

    persons = sorted(os.listdir(NEW_DIR))
    print("\nğŸ†• åµæ¸¬åˆ°æ–°å¢äººç‰©è³‡æ–™å¤¾ï¼š", persons)

    for person in persons:
        p_dir = os.path.join(NEW_DIR, person)
        if not os.path.isdir(p_dir):
            continue

        images = os.listdir(p_dir)
        print(f"\nğŸ“¸ æ–°å¢ {person}: {len(images)} å¼µ")

        for img_name in tqdm(images):
            img_path = os.path.join(p_dir, img_name)
            img = imread_safe(img_path)
            if img is None:
                continue

            faces = app.get(img)
            if faces:
                X_new.append(faces[0].normed_embedding)
                y_new.append(person)

    return np.array(X_new), np.array(y_new)


# ============================================================
# ğŸ”¥ Step 3ï¼šé‡è¨“ KNN / SVM / Centers
# ============================================================
def save_pickle(obj, filename):
    path = os.path.join(MODEL_DIR, filename)
    with open(path, "wb") as f:
        pickle.dump(obj, f)
    print("ğŸ’¾ saved:", path)


def train_incremental():
    # è®€å–èˆŠè³‡æ–™
    X_old, y_old = load_old_data()

    # è®€å–æ–°è³‡æ–™
    X_new, y_new = load_new_embeddings()

    # åˆä½µ
    X = np.concatenate([X_old, X_new], axis=0)
    y = np.concatenate([y_old, y_new], axis=0)

    print("\nğŸ“¦ åˆä½µå¾Œè³‡æ–™é‡ï¼š", X.shape)

    # è¨“ç·´ KNN
    print("\nğŸš€ Training KNN ...")
    knn = KNeighborsClassifier(n_neighbors=5)
    knn.fit(X, y)

    # è¨“ç·´ SVM
    print("\nğŸš€ Training SVM ...")
    svm = SVC(kernel="linear", probability=True)
    svm.fit(X, y)

    # è¨ˆç®— Cosine Centers
    print("\nğŸš€ Updating Centers ...")
    centers = {}
    for person in np.unique(y):
        centers[person] = X[y == person].mean(axis=0)

    # å„²å­˜
    print("\nğŸ’¾ Saving updated models...")
    save_pickle(knn, "knn.pkl")
    save_pickle(svm, "svm.pkl")
    save_pickle(centers, "centers.pkl")

    # è¨˜å¾—æ›´æ–° X / y
    np.save(os.path.join(MODEL_DIR, "X.npy"), X)
    np.save(os.path.join(MODEL_DIR, "y.npy"), y)

    print("\nğŸ‰ å¢é‡è¨“ç·´å®Œæˆï¼")


if __name__ == "__main__":
    train_incremental()
